#!/usr/bin/env python3
"""
SAM3 + Qwen VLM ç»“åˆæ‰“ç‚¹åº”ç”¨
åŠŸèƒ½ï¼š
1. åŠ è½½å›¾ç‰‡
2. SAM3æ–‡æœ¬è¾“å…¥ â†’ è·å¾—mask
3. VLMæ–‡æœ¬è¾“å…¥ â†’ è·å¾—bbox (åŒ…å«åæ ‡ç³»å½’ä¸€åŒ–ä¿®å¤)
4. è®¡ç®—maskå’Œbboxäº¤é›†
5. å¯è§†åŒ–å±•ç¤ºæ‰€æœ‰ç»“æœ
"""

import base64
import io
import json
import os
import threading
import re  # æ·»åŠ æ­£åˆ™æ”¯æŒ
import tkinter as tk
from tkinter import filedialog, messagebox, scrolledtext, ttk
from typing import Any

import cv2
import numpy as np
import requests
from PIL import Image, ImageDraw, ImageTk

# ========== SAM3 é…ç½® ==========

SAM3_SERVER_URL = "http://101.132.143.105:5081"



# ========== Qwen VLM é…ç½® ==========

QWEN_BASE_URL = (

"http://1054059136692489.cn-beijing.pai-eas.aliyuncs.com/api/predict/qwen3_vl_235b_a22b_instruct_h20"

)

QWEN_CHAT_URL = f"{QWEN_BASE_URL}/v1/chat/completions"

QWEN_AUTH_TOKEN = "N2I4Mjc0MjkxN2M1Y2NmYzUwNzE0YmEzNjMwOTAwNTE0OWE2YWRjNg=="

QWEN_MODEL_ID = "Qwen3-VL-235B-A22B-Instruct"

QWEN_SYSTEM_PROMPT = "ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€åŠ©æ‰‹ã€‚"




def encode_image_to_base64(image: Image.Image) -> str:
    """å°†PILå›¾åƒç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
    buffer = io.BytesIO()
    image.save(buffer, format="PNG")
    return base64.b64encode(buffer.getvalue()).decode("utf-8")


class SamVlmApp(ttk.Frame):
    def __init__(self, master: tk.Tk) -> None:
        super().__init__(master, padding=12)
        self.pack(fill="both", expand=True)

        self.master = master
        self.master.title("SAM3 + Qwen VLM æ‰“ç‚¹åº”ç”¨ (Fixed)")

        # çŠ¶æ€å˜é‡
        self.current_image: Image.Image | None = None
        self.image_path: str | None = None
        self.base_frame_image: Image.Image | None = None
        self.sam3_mask: np.ndarray | None = None
        self.vlm_bbox: tuple[int, int, int, int] | None = None
        self.intersection_mask: np.ndarray | None = None
        self.cap: cv2.VideoCapture | None = None
        self.video_path: str | None = None
        self.total_frames: int = 0
        self.current_frame_index: int = 0
        self.is_image_source: bool = True
        self.rotation_steps: int = 0

        self.frame_slider: ttk.Scale | None = None
        self.frame_info_var = tk.StringVar(value="å¸§: -/-")
        self._slider_programmatic = False

        # æ„å»ºUI
        self._build_ui()

    def _build_ui(self) -> None:
        """æ„å»ºç”¨æˆ·ç•Œé¢"""
        # ========== é¡¶éƒ¨ï¼šæ–‡ä»¶åŠ è½½ ==========
        file_frame = ttk.LabelFrame(self, text="åª’ä½“åŠ è½½")
        file_frame.pack(fill="x", pady=(0, 8))

        load_btn = ttk.Button(file_frame, text="åŠ è½½å›¾ç‰‡/è§†é¢‘", command=self.load_media)
        load_btn.pack(side="left", padx=8, pady=8)

        ttk.Button(
            file_frame, text="â†º é€†æ—¶é’ˆ90Â°", command=lambda: self.rotate_image(-1)
        ).pack(side="left", padx=(0, 4))
        ttk.Button(
            file_frame, text="â†» é¡ºæ—¶é’ˆ90Â°", command=lambda: self.rotate_image(1)
        ).pack(side="left")

        self.file_label = ttk.Label(file_frame, text="æœªåŠ è½½åª’ä½“")
        self.file_label.pack(side="left", padx=8)

        slider_frame = ttk.Frame(self)
        slider_frame.pack(fill="x", pady=(0, 8))
        ttk.Label(slider_frame, textvariable=self.frame_info_var, width=12).pack(
            side="left", padx=(8, 4)
        )
        self.frame_slider = ttk.Scale(
            slider_frame, from_=0, to=0, orient="horizontal", command=self._on_frame_slider
        )
        self.frame_slider.pack(fill="x", expand=True, padx=(0, 8))
        self.frame_slider.state(["disabled"])

        # ========== ä¸­éƒ¨ï¼šè¾“å…¥åŒºåŸŸ ==========
        input_frame = ttk.LabelFrame(self, text="æ¨¡å‹è¾“å…¥")
        input_frame.pack(fill="x", pady=(0, 8))

        # SAM3 è¾“å…¥
        sam3_row = ttk.Frame(input_frame)
        sam3_row.pack(fill="x", padx=8, pady=(8, 4))
        ttk.Label(sam3_row, text="SAM3 Prompt:", width=15).pack(side="left")
        self.sam3_entry = ttk.Entry(sam3_row)
        self.sam3_entry.pack(side="left", fill="x", expand=True, padx=(4, 4))
        ttk.Button(sam3_row, text="ç”ŸæˆMask", command=self.run_sam3).pack(side="left")

        # VLM è¾“å…¥
        vlm_row = ttk.Frame(input_frame)
        vlm_row.pack(fill="x", padx=8, pady=(4, 8))
        ttk.Label(vlm_row, text="VLM Prompt:", width=15).pack(side="left")
        self.vlm_entry = ttk.Entry(vlm_row)
        self.vlm_entry.pack(side="left", fill="x", expand=True, padx=(4, 4))
        ttk.Button(vlm_row, text="é¢„æµ‹Bbox", command=self.run_vlm).pack(side="left")

        # å¤„ç†æŒ‰é’®
        process_row = ttk.Frame(input_frame)
        process_row.pack(fill="x", padx=8, pady=(4, 8))
        ttk.Button(
            process_row, text="ğŸš€ è¿è¡Œå…¨æµç¨‹", command=self.run_full_pipeline
        ).pack(side="left", padx=(0, 8))
        ttk.Button(process_row, text="è®¡ç®—äº¤é›†", command=self.compute_intersection).pack(
            side="left"
        )

        # ========== å¯è§†åŒ–åŒºåŸŸ ==========
        viz_frame = ttk.LabelFrame(self, text="å¯è§†åŒ–ç»“æœ")
        viz_frame.pack(fill="both", expand=True, pady=(0, 8))

        # åˆ›å»º2x2ç½‘æ ¼æ˜¾ç¤º
        viz_grid = ttk.Frame(viz_frame)
        viz_grid.pack(fill="both", expand=True, padx=8, pady=8)

        # é…ç½®ç½‘æ ¼æƒé‡
        viz_grid.columnconfigure(0, weight=1)
        viz_grid.columnconfigure(1, weight=1)
        viz_grid.rowconfigure(0, weight=1)
        viz_grid.rowconfigure(1, weight=1)

        # å·¦ä¸Šï¼šåŸå›¾
        frame_original = ttk.LabelFrame(viz_grid, text="åŸå›¾")
        frame_original.grid(row=0, column=0, sticky="nsew", padx=2, pady=2)
        self.canvas_original = tk.Canvas(
            frame_original, bg="black", highlightthickness=0
        )
        self.canvas_original.pack(fill="both", expand=True)

        # å³ä¸Šï¼šSAM3 Mask
        frame_sam = ttk.LabelFrame(viz_grid, text="SAM3 Mask")
        frame_sam.grid(row=0, column=1, sticky="nsew", padx=2, pady=2)
        self.canvas_sam = tk.Canvas(frame_sam, bg="black", highlightthickness=0)
        self.canvas_sam.pack(fill="both", expand=True)

        # å·¦ä¸‹ï¼šVLM Bbox
        frame_vlm = ttk.LabelFrame(viz_grid, text="VLM Bbox")
        frame_vlm.grid(row=1, column=0, sticky="nsew", padx=2, pady=2)
        self.canvas_vlm = tk.Canvas(frame_vlm, bg="black", highlightthickness=0)
        self.canvas_vlm.pack(fill="both", expand=True)

        # å³ä¸‹ï¼šäº¤é›†ç»“æœ
        frame_intersection = ttk.LabelFrame(viz_grid, text="äº¤é›†ç»“æœ")
        frame_intersection.grid(row=1, column=1, sticky="nsew", padx=2, pady=2)
        self.canvas_intersection = tk.Canvas(
            frame_intersection, bg="black", highlightthickness=0
        )
        self.canvas_intersection.pack(fill="both", expand=True)

        # ========== åº•éƒ¨ï¼šçŠ¶æ€å’Œæ—¥å¿— ==========
        status_frame = ttk.Frame(self)
        status_frame.pack(fill="x", pady=(0, 8))

        self.status_var = tk.StringVar(value="ç­‰å¾…åŠ è½½å›¾ç‰‡...")
        ttk.Label(status_frame, textvariable=self.status_var).pack(
            side="left", fill="x", expand=True
        )

        log_frame = ttk.LabelFrame(self, text="æ—¥å¿—")
        log_frame.pack(fill="both", expand=True)

        self.log_box = scrolledtext.ScrolledText(log_frame, height=6, wrap="word")
        self.log_box.pack(fill="both", expand=True, padx=8, pady=8)
        self.log_box.configure(state="disabled")

    def log(self, message: str) -> None:
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        self.log_box.configure(state="normal")
        self.log_box.insert("end", f"{message}\n")
        self.log_box.see("end")
        self.log_box.configure(state="disabled")

    def load_media(self) -> None:
        """åŠ è½½å›¾ç‰‡æˆ–è§†é¢‘"""
        filepath = filedialog.askopenfilename(
            title="é€‰æ‹©å›¾ç‰‡æˆ–è§†é¢‘",
            filetypes=[
                ("åª’ä½“æ–‡ä»¶", "*.jpg *.jpeg *.png *.bmp *.webp *.mp4 *.avi *.mov *.mkv *.mpg *.mpeg *.wmv *.flv *.webm"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*"),
            ],
        )
        if not filepath:
            return

        ext = os.path.splitext(filepath)[1].lower()
        video_exts = {".mp4", ".avi", ".mov", ".mkv", ".mpg", ".mpeg", ".wmv", ".flv", ".webm"}

        if ext in video_exts:
            self._load_video_file(filepath)
        else:
            self._load_image_file(filepath)

    def _release_video(self) -> None:
        if self.cap:
            self.cap.release()
            self.cap = None

    def _configure_slider(self, to_value: int, enabled: bool) -> None:
        if not self.frame_slider:
            return
        self._slider_programmatic = True
        self.frame_slider.configure(from_=0, to=to_value)
        self.frame_slider.set(0)
        self._slider_programmatic = False
        if enabled:
            self.frame_slider.state(["!disabled"])
        else:
            self.frame_slider.state(["disabled"])

    def _load_image_file(self, filepath: str) -> None:
        try:
            image = Image.open(filepath).convert("RGB")
        except Exception as exc:
            messagebox.showerror("é”™è¯¯", f"åŠ è½½å›¾ç‰‡å¤±è´¥: {exc}")
            self.log(f"âœ— åŠ è½½å¤±è´¥: {exc}")
            return

        self._release_video()
        self.is_image_source = True
        self.video_path = None
        self.image_path = filepath
        self.base_frame_image = image
        self.rotation_steps = 0
        self.total_frames = 1
        self.current_frame_index = 0
        self._configure_slider(0, enabled=False)
        self.frame_info_var.set("å¸§: 1/1")
        self.file_label.config(text=os.path.basename(filepath))
        self.status_var.set(f"å·²åŠ è½½å›¾ç‰‡: {os.path.basename(filepath)}")
        self.log(f"âœ“ åŠ è½½å›¾ç‰‡: {filepath}")
        self._clear_results()
        self._apply_rotation_to_current_frame()

    def _load_video_file(self, filepath: str) -> None:
        cap = cv2.VideoCapture(filepath)
        if not cap.isOpened():
            messagebox.showerror("é”™è¯¯", "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
            self.log("âœ— è§†é¢‘æ‰“å¼€å¤±è´¥")
            return
        frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if frames <= 0:
            cap.release()
            messagebox.showerror("é”™è¯¯", "æ— æ³•è¯»å–è§†é¢‘å¸§æ•°")
            self.log("âœ— è§†é¢‘å¸§æ•°æ— æ•ˆ")
            return

        self._release_video()
        self.cap = cap
        self.is_image_source = False
        self.video_path = filepath
        self.image_path = filepath
        self.rotation_steps = 0
        self.total_frames = frames
        self.current_frame_index = 0
        self._configure_slider(max(frames - 1, 0), enabled=True)
        self.file_label.config(text=f"{os.path.basename(filepath)} (è§†é¢‘)")
        self.status_var.set(f"å·²åŠ è½½è§†é¢‘: {os.path.basename(filepath)}")
        self.log(f"âœ“ åŠ è½½è§†é¢‘: {filepath} (å¸§æ•° {frames})")
        self._display_frame(0)

    def _display_frame(self, frame_index: int) -> None:
        if self.is_image_source:
            if self.base_frame_image:
                self.current_frame_index = 0
                self._clear_results()
                self._apply_rotation_to_current_frame()
                self.frame_info_var.set("å¸§: 1/1")
            return

        if not self.cap:
            return

        if frame_index < 0 or frame_index >= self.total_frames:
            frame_index = max(0, min(frame_index, self.total_frames - 1))

        if not self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index):
            self.log(f"âœ— æ— æ³•å®šä½åˆ°å¸§ {frame_index}")
            return

        success, frame = self.cap.read()
        if not success or frame is None:
            self.log(f"âœ— æ— æ³•è¯»å–å¸§ {frame_index}")
            return

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image = Image.fromarray(frame_rgb)
        self.base_frame_image = image
        self.current_frame_index = frame_index
        self._clear_results()
        self._apply_rotation_to_current_frame()
        self._update_frame_info()
        if self.frame_slider and not self._slider_programmatic:
            self._slider_programmatic = True
            self.frame_slider.set(frame_index)
            self._slider_programmatic = False

    def _update_frame_info(self) -> None:
        if self.is_image_source or self.total_frames <= 1:
            self.frame_info_var.set("å¸§: 1/1")
        else:
            self.frame_info_var.set(
                f"å¸§: {self.current_frame_index + 1}/{self.total_frames}"
            )

    def _on_frame_slider(self, value: str) -> None:
        if self._slider_programmatic or self.is_image_source:
            return
        index = int(float(value))
        if index != self.current_frame_index:
            self._display_frame(index)

    def _display_image(
        self, canvas: tk.Canvas, image: Image.Image, bbox: tuple | None = None
    ) -> None:
        """åœ¨ç”»å¸ƒä¸Šæ˜¾ç¤ºå›¾ç‰‡"""
        # ç¼©æ”¾å›¾ç‰‡ä»¥é€‚åº”ç”»å¸ƒ
        max_size = 400
        display_img = image.copy()
        orig_w, orig_h = image.size
        display_img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
        disp_w, disp_h = display_img.size

        # å¦‚æœæœ‰bboxï¼Œç»˜åˆ¶åœ¨å›¾ä¸Š
        if bbox:
            draw = ImageDraw.Draw(display_img)
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼šæ˜¾ç¤ºå°ºå¯¸ / çœŸå®å°ºå¯¸
            scale_x = disp_w / orig_w
            scale_y = disp_h / orig_h
            
            x1, y1, x2, y2 = bbox
            scaled_bbox = (
                int(x1 * scale_x),
                int(y1 * scale_y),
                int(x2 * scale_x),
                int(y2 * scale_y),
            )
            # ç¡®ä¿bboxåœ¨æ˜¾ç¤ºèŒƒå›´å†…
            scaled_bbox = (
                max(0, min(scaled_bbox[0], disp_w - 1)),
                max(0, min(scaled_bbox[1], disp_h - 1)),
                max(0, min(scaled_bbox[2], disp_w - 1)),
                max(0, min(scaled_bbox[3], disp_h - 1)),
            )
            draw.rectangle(scaled_bbox, outline="red", width=3)

        photo = ImageTk.PhotoImage(display_img)
        canvas.delete("all")
        canvas.config(width=display_img.width, height=display_img.height)
        canvas.create_image(0, 0, anchor="nw", image=photo)
        canvas.image = photo  # ä¿æŒå¼•ç”¨

    def _clear_results(self) -> None:
        self.sam3_mask = None
        self.vlm_bbox = None
        self.intersection_mask = None
        self.canvas_sam.delete("all")
        self.canvas_vlm.delete("all")
        self.canvas_intersection.delete("all")

    def rotate_image(self, steps: int) -> None:
        if not self.base_frame_image:
            return
        self.rotation_steps = (self.rotation_steps + steps) % 4
        self._clear_results()
        self._apply_rotation_to_current_frame()
        self.log("â†» å›¾åƒå·²æ—‹è½¬")

    def _apply_rotation_to_current_frame(self) -> None:
        if not self.base_frame_image:
            return
        rotated = self._rotate_image(self.base_frame_image, self.rotation_steps)
        self.current_image = rotated
        self._display_image(self.canvas_original, rotated)

    def _rotate_image(self, image: Image.Image, steps: int) -> Image.Image:
        steps = steps % 4
        if steps == 0:
            return image.copy()
        if steps == 1:  # é¡ºæ—¶é’ˆ90Â°
            return image.transpose(Image.Transpose.ROTATE_270)
        if steps == 2:
            return image.transpose(Image.Transpose.ROTATE_180)
        if steps == 3:
            return image.transpose(Image.Transpose.ROTATE_90)
        return image.copy()

    def run_sam3(self) -> None:
        """è°ƒç”¨SAM3è·å–mask"""
        if not self.current_image:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½å›¾ç‰‡æˆ–è§†é¢‘å¸§")
            return

        text_prompt = self.sam3_entry.get().strip()
        if not text_prompt:
            messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥SAM3 prompt")
            return

        self.status_var.set("æ­£åœ¨è°ƒç”¨SAM3...")
        self.log(f"â†’ SAM3 è¯·æ±‚: {text_prompt}")

        def worker():
            try:
                if not self.current_image:
                    raise RuntimeError("æœªæ‰¾åˆ°å·²åŠ è½½çš„å›¾åƒæ•°æ®")

                image_b64 = encode_image_to_base64(self.current_image)
                payload: dict[str, Any] = {"image": image_b64, "text_prompt": text_prompt}
                response = requests.post(
                    f"{SAM3_SERVER_URL}/segment",
                    json=payload,
                    headers={"Content-Type": "application/json"},
                    timeout=60,
                )

                if response.status_code != 200:
                    raise RuntimeError(
                        f"SAM3 è¯·æ±‚å¤±è´¥: {response.status_code} {response.text}"
                    )

                result = response.json()
                if not result.get("success"):
                    raise RuntimeError(result.get("error", "æœªçŸ¥é”™è¯¯"))

                num_detections = result.get("num_detections", 0)
                self.log(f"âœ“ SAM3æ£€æµ‹åˆ° {num_detections} ä¸ªç›®æ ‡")

                # åˆå¹¶æ‰€æœ‰mask
                if num_detections > 0 and "detections" in result:
                    original_np = np.array(self.current_image)
                    h, w = original_np.shape[:2]
                    combined_mask = np.zeros((h, w), dtype=np.uint8)

                    for detection in result["detections"]:
                        mask_data = base64.b64decode(detection["mask"])
                        mask_img = Image.open(io.BytesIO(mask_data))
                        mask_np = np.array(mask_img)

                        if mask_np.shape != (h, w):
                            mask_img = mask_img.resize((w, h), Image.NEAREST)
                            mask_np = np.array(mask_img)

                        combined_mask = np.maximum(combined_mask, mask_np)

                    self.sam3_mask = combined_mask

                    # å¯è§†åŒ–mask
                    self.master.after(0, lambda: self._visualize_sam3_mask())
                    self.master.after(
                        0, lambda: self.status_var.set("SAM3å¤„ç†å®Œæˆ")
                    )
                else:
                    self.master.after(0, lambda: self.log("âš  SAM3æœªæ£€æµ‹åˆ°ç›®æ ‡"))
                    self.master.after(
                        0, lambda: self.status_var.set("SAM3æœªæ£€æµ‹åˆ°ç›®æ ‡")
                    )

            except Exception as exc:
                self.master.after(0, lambda e=exc: self.log(f"âœ— SAM3é”™è¯¯: {e}"))
                self.master.after(0, lambda e=exc: messagebox.showerror("é”™è¯¯", str(e)))
                self.master.after(0, lambda e=exc: self.status_var.set("SAM3å¤„ç†å¤±è´¥"))

        threading.Thread(target=worker, daemon=True).start()

    def _visualize_sam3_mask(self) -> None:
        """å¯è§†åŒ–SAM3 maskç»“æœ"""
        if self.sam3_mask is None or self.current_image is None:
            return

        # åˆ›å»ºå½©è‰²maskå åŠ å›¾
        original_np = np.array(self.current_image)
        mask_colored = np.zeros_like(original_np)
        mask_colored[self.sam3_mask > 128] = [0, 255, 0]  # ç»¿è‰²mask

        # åŠé€æ˜å åŠ 
        overlay = cv2.addWeighted(original_np, 0.6, mask_colored, 0.4, 0)
        overlay_img = Image.fromarray(overlay)

        self._display_image(self.canvas_sam, overlay_img)
        self.log("âœ“ SAM3 maskå¯è§†åŒ–å®Œæˆ")

    def run_vlm(self) -> None:
        """è°ƒç”¨Qwen VLMè·å–bbox"""
        if not self.current_image:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½å›¾ç‰‡")
            return

        text_prompt = self.vlm_entry.get().strip()
        if not text_prompt:
            messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥VLM prompt")
            return

        self.status_var.set("æ­£åœ¨è°ƒç”¨VLM...")
        self.log(f"â†’ VLM è¯·æ±‚: {text_prompt}")

        def worker():
            try:
                # ç¼–ç å›¾ç‰‡
                frame_b64 = encode_image_to_base64(self.current_image)

                # ä¿®æ”¹Promptï¼Œå¼ºåˆ¶è¦æ±‚JSONæ ¼å¼è¾“å‡º
                final_prompt = text_prompt + "\nè¯·è¾“å‡ºJSONæ ¼å¼ï¼Œå¿…é¡»åŒ…å«é”® 'bbox_2d'ã€‚"

                # è°ƒç”¨Qwen API
                headers = {
                    "Authorization": f"Bearer {QWEN_AUTH_TOKEN}",
                    "Content-Type": "application/json",
                }
                payload = {
                    "model": QWEN_MODEL_ID,
                    "messages": [
                        {"role": "system", "content": QWEN_SYSTEM_PROMPT},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": final_prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpg;base64,{frame_b64}"
                                    },
                                },
                            ],
                        },
                    ],
                    "temperature": 0.0,
                }

                response = requests.post(
                    QWEN_CHAT_URL, headers=headers, json=payload, timeout=60
                )

                if response.status_code >= 400:
                    raise RuntimeError(
                        f"VLMè¯·æ±‚å¤±è´¥ {response.status_code}: {response.text}"
                    )

                data = response.json()
                choices = data.get("choices")
                if not choices:
                    raise RuntimeError("VLMè¿”å›ç©ºç»“æœ")

                message = choices[0].get("message", {})
                content = message.get("content", "")

                self.log(f"âœ“ VLMå“åº”: {content}")

                # è§£æbbox (åŸå§‹ 0-1000 åæ ‡ç³»)
                bbox_raw = self._parse_bbox(content)
                
                if bbox_raw:
                    # [å…³é”®ä¿®å¤]ï¼šå°† 0-1000 çš„å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºçœŸå®åƒç´ åæ ‡
                    w, h = self.current_image.size
                    
                    # è½¬æ¢å…¬å¼: çœŸå®åæ ‡ = (å½’ä¸€åŒ–åæ ‡ / 1000) * çœŸå®å°ºå¯¸
                    x1 = int(bbox_raw[0] / 1000 * w)
                    y1 = int(bbox_raw[1] / 1000 * h)
                    x2 = int(bbox_raw[2] / 1000 * w)
                    y2 = int(bbox_raw[3] / 1000 * h)
                    
                    self.vlm_bbox = (x1, y1, x2, y2)
                    self.log(f"âœ“ åæ ‡è½¬æ¢: {bbox_raw} (1000ç³») -> {self.vlm_bbox} (åƒç´ ç³»)")

                    self.master.after(0, lambda: self._visualize_vlm_bbox())
                    self.master.after(0, lambda: self.status_var.set("VLMå¤„ç†å®Œæˆ"))
                else:
                    self.master.after(0, lambda: self.log("âš  æœªèƒ½ä»VLMå“åº”ä¸­è§£æbbox"))
                    self.master.after(
                        0, lambda: self.status_var.set("VLMæœªè¿”å›æœ‰æ•ˆbbox")
                    )

            except Exception as exc:
                self.master.after(0, lambda: self.log(f"âœ— VLMé”™è¯¯: {exc}"))
                self.master.after(0, lambda: messagebox.showerror("é”™è¯¯", str(exc)))
                self.master.after(0, lambda: self.status_var.set("VLMå¤„ç†å¤±è´¥"))

        threading.Thread(target=worker, daemon=True).start()

    def _parse_bbox(self, text: str) -> tuple[int, int, int, int] | None:
        """
        è§£æbboxï¼Œæ”¯æŒ JSON æ ¼å¼æå–å’Œæ­£åˆ™å…œåº•
        ç›®æ ‡æ ¼å¼: [x1, y1, x2, y2]
        """
        # --- ç­–ç•¥ 1: å°è¯•è§£æ JSON (é’ˆå¯¹ Qwen çš„æ ‡å‡†è¾“å‡ºæ ¼å¼) ---
        try:
            clean_text = text.strip()
            # æ¸…ç† Markdown ä»£ç å—æ ‡è®°
            if "```json" in clean_text:
                clean_text = clean_text.split("```json")[1].split("```")[0].strip()
            elif "```" in clean_text:
                clean_text = clean_text.split("```")[1].split("```")[0].strip()
            
            # å°è¯•åŠ è½½ JSON
            data = json.loads(clean_text)

            # å¤„ç†åˆ—è¡¨åŒ…è£¹çš„æƒ…å†µ [{"bbox_2d": [...]}]
            if isinstance(data, list) and len(data) > 0:
                item = data[0]
                if isinstance(item, dict) and "bbox_2d" in item:
                    bbox = item["bbox_2d"]
                    if len(bbox) == 4:
                        return tuple(map(int, bbox))
            
            # å¤„ç†ç›´æ¥æ˜¯å­—å…¸çš„æƒ…å†µ {"bbox_2d": [...]}
            elif isinstance(data, dict) and "bbox_2d" in data:
                bbox = data["bbox_2d"]
                if len(bbox) == 4:
                    return tuple(map(int, bbox))

        except Exception as e:
            print(f"DEBUG: JSONè§£æå°è¯•å¤±è´¥: {e}")

        # --- ç­–ç•¥ 2: æ­£åˆ™è¡¨è¾¾å¼å…œåº• (é’ˆå¯¹éæ ‡å‡†çº¯æ–‡æœ¬å›å¤) ---
        matches = re.findall(r"\[([\d\s,]+)\]", text)
        for match in matches:
            parts = [p.strip() for p in match.split(",")]
            parts = [p for p in parts if p]
            if len(parts) == 4:
                try:
                    coords = [float(p) for p in parts]
                    return (int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3]))
                except ValueError:
                    continue
        
        return None

    def _visualize_vlm_bbox(self) -> None:
        """å¯è§†åŒ–VLM bboxç»“æœ"""
        if self.vlm_bbox is None or self.current_image is None:
            return

        self._display_image(self.canvas_vlm, self.current_image, self.vlm_bbox)
        self.log(f"âœ“ VLM bboxå¯è§†åŒ–å®Œæˆ")

    def compute_intersection(self) -> None:
        """è®¡ç®—maskå’Œbboxçš„äº¤é›†"""
        if self.sam3_mask is None:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆè¿è¡ŒSAM3è·å–mask")
            return

        if self.vlm_bbox is None:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆè¿è¡ŒVLMè·å–bbox")
            return

        self.status_var.set("æ­£åœ¨è®¡ç®—äº¤é›†...")
        self.log("â†’ è®¡ç®—maskå’Œbboxäº¤é›†...")

        try:
            # åˆ›å»ºbbox mask
            h, w = self.sam3_mask.shape
            bbox_mask = np.zeros((h, w), dtype=np.uint8)
            x1, y1, x2, y2 = self.vlm_bbox

            # ç¡®ä¿bboxåœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, min(x1, w - 1))
            y1 = max(0, min(y1, h - 1))
            x2 = max(0, min(x2, w - 1))
            y2 = max(0, min(y2, h - 1))

            bbox_mask[y1:y2, x1:x2] = 255

            # è®¡ç®—äº¤é›†
            self.intersection_mask = np.logical_and(
                self.sam3_mask > 128, bbox_mask > 128
            ).astype(np.uint8) * 255

            # å¯è§†åŒ–äº¤é›†
            self._visualize_intersection()
            self.status_var.set("äº¤é›†è®¡ç®—å®Œæˆ")
            self.log("âœ“ äº¤é›†è®¡ç®—å®Œæˆ")

        except Exception as exc:
            self.log(f"âœ— äº¤é›†è®¡ç®—é”™è¯¯: {exc}")
            messagebox.showerror("é”™è¯¯", f"äº¤é›†è®¡ç®—å¤±è´¥: {exc}")
            self.status_var.set("äº¤é›†è®¡ç®—å¤±è´¥")

    def _visualize_intersection(self) -> None:
        """å¯è§†åŒ–äº¤é›†ç»“æœ"""
        if self.intersection_mask is None or self.current_image is None:
            return

        # åˆ›å»ºå½©è‰²maskå åŠ å›¾ + bbox
        original_np = np.array(self.current_image)
        result_img = original_np.copy()

        # å åŠ äº¤é›†maskï¼ˆé»„è‰²ï¼‰
        mask_colored = np.zeros_like(original_np)
        mask_colored[self.intersection_mask > 0] = [255, 255, 0]  # é»„è‰²
        result_img = cv2.addWeighted(result_img, 0.6, mask_colored, 0.4, 0)

        result_pil = Image.fromarray(result_img)

        # ç»˜åˆ¶bbox
        self._display_image(self.canvas_intersection, result_pil, self.vlm_bbox)

        # ç»Ÿè®¡äº¤é›†åƒç´ æ•°
        intersection_pixels = np.sum(self.intersection_mask > 0)
        sam_pixels = np.sum(self.sam3_mask > 128)
        self.log(
            f"âœ“ äº¤é›†åƒç´ : {intersection_pixels} / SAMæ€»åƒç´ : {sam_pixels} "
            f"({100*intersection_pixels/max(sam_pixels, 1):.1f}%)"
        )

    def run_full_pipeline(self) -> None:
        """è¿è¡Œå®Œæ•´æµç¨‹ï¼šSAM3 â†’ VLM â†’ äº¤é›†"""
        if not self.current_image:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½å›¾ç‰‡")
            return

        sam_prompt = self.sam3_entry.get().strip()
        vlm_prompt = self.vlm_entry.get().strip()

        if not sam_prompt or not vlm_prompt:
            messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥SAM3å’ŒVLMçš„prompt")
            return

        self.log("=" * 50)
        self.log("ğŸš€ å¼€å§‹è¿è¡Œå…¨æµç¨‹")

        def worker():
            # 1. è¿è¡ŒSAM3
            self.master.after(0, lambda: self.run_sam3())

            # ç­‰å¾…SAM3å®Œæˆï¼ˆç®€å•çš„è½®è¯¢æ£€æŸ¥ï¼‰
            import time

            max_wait = 60  # æœ€å¤šç­‰å¾…60ç§’
            wait_time = 0
            while self.sam3_mask is None and wait_time < max_wait:
                time.sleep(0.5)
                wait_time += 0.5

            if self.sam3_mask is None:
                self.master.after(0, lambda: self.log("âœ— SAM3è¶…æ—¶"))
                return

            # 2. è¿è¡ŒVLM
            self.master.after(0, lambda: self.run_vlm())

            # ç­‰å¾…VLMå®Œæˆ
            wait_time = 0
            while self.vlm_bbox is None and wait_time < max_wait:
                time.sleep(0.5)
                wait_time += 0.5

            if self.vlm_bbox is None:
                self.master.after(0, lambda: self.log("âœ— VLMè¶…æ—¶"))
                return

            # 3. è®¡ç®—äº¤é›†
            time.sleep(0.5)  # çŸ­æš‚ç­‰å¾…ç¡®ä¿UIæ›´æ–°
            self.master.after(0, lambda: self.compute_intersection())
            self.master.after(0, lambda: self.log("ğŸ‰ å…¨æµç¨‹å®Œæˆ"))

        threading.Thread(target=worker, daemon=True).start()


def main() -> None:
    root = tk.Tk()
    try:
        ttk.Style().theme_use("clam")
    except tk.TclError:
        pass
    SamVlmApp(root)
    root.mainloop()


if __name__ == "__main__":
    main()
