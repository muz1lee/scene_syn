from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, List

import yaml

from scenethesis.modules.planner import CoarseScenePlanner
from scenethesis.services.providers import LLMConfig, GeminiProvider

CONFIG_PATH = Path("config.yaml")


def load_config(path: Path = CONFIG_PATH) -> Dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {path} ä¸å­˜åœ¨ï¼Œè¯·åˆ›å»º config.yaml")
    with path.open("r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def _save_plan(plan_json: str, output_dir: str | Path | None) -> Path:
    base_dir = Path(__file__).resolve().parent
    target_dir = Path(output_dir) if output_dir else base_dir / "output"
    target_dir.mkdir(parents=True, exist_ok=True)
    filename = "planner_output.json"
    file_path = target_dir / filename
    file_path.write_text(plan_json, encoding="utf-8")
    return file_path


def run_scenethesis_system(config: Dict[str, Any]) -> None:
    prompt = config.get("prompt", "A simple room")
    assets = config.get("db_assets", [])
    model_name = config.get("model_name", "gemini-3-flash")
    output_dir = config.get("output_dir")

    if not assets:
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘ db_assets åˆ—è¡¨")

    print("ğŸš€ [ä¸»å¾ªç¯] å¯åŠ¨ Scenethesis Planner å•å…ƒæµ‹è¯•...")
    llm_config = LLMConfig(model=model_name)
    llm_provider = GeminiProvider(config=llm_config)
    planner = CoarseScenePlanner(assets, llm_provider)

    plan = planner.run_pipeline(prompt)
    plan_json = json.dumps(plan, ensure_ascii=False, indent=2)
    print("âœ… [ç»“æœ] ç²—çº§è§„åˆ’è¾“å‡ºï¼š")
    print(plan_json)

    output_path = _save_plan(plan_json, output_dir)
    print(f"ğŸ’¾ [ä¿å­˜] è§„åˆ’ç»“æœå·²å†™å…¥: {output_path}")


if __name__ == "__main__":
    cfg = load_config()
    run_scenethesis_system(cfg)
