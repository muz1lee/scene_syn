from __future__ import annotations

from dataclasses import dataclass
from io import BytesIO
from typing import Optional

import numpy as np
from PIL import Image


@dataclass
class DepthEstimation:
    depth_map: np.ndarray | None
    min_depth: float | None
    max_depth: float | None
    median_depth: float | None
    raw: dict


class DepthProLocal:
    """
    Depth Pro æœ¬åœ°æ¨ç†å®ç°ï¼Œç›´æ¥è°ƒç”¨æ¨¡å‹è€Œé HTTP APIã€‚
    é€‚ç”¨äº GPU æœåŠ¡å™¨éƒ¨ç½²åœºæ™¯ã€‚
    """

    def __init__(
        self,
        device: str = "cuda",
        model_path: Optional[str] = None,
    ) -> None:
        """
        Args:
            device: 'cuda', 'cpu', æˆ– 'mps' (Apple Silicon)
            model_path: è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ä¸‹è½½ï¼‰
        """
        self.device = device
        self.model = None
        self.transform = None
        self._load_model(model_path)

    def _load_model(self, model_path: Optional[str]) -> None:
        """å»¶è¿ŸåŠ è½½æ¨¡å‹ï¼Œé¿å…å¯¼å…¥æ—¶å°±å ç”¨ GPU"""
        try:
            import depth_pro
            import torch

            print(f"ğŸ”§ [DepthProLocal] åŠ è½½ Depth Pro æ¨¡å‹åˆ° {self.device}...")

            # åŠ è½½æ¨¡å‹å’Œé¢„å¤„ç†å™¨
            if model_path:
                self.model, self.transform = depth_pro.create_model_and_transforms(
                    checkpoint_path=model_path,
                    device=self.device,
                )
            else:
                # è‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
                self.model, self.transform = depth_pro.create_model_and_transforms(
                    device=self.device,
                )

            self.model.eval()
            print("âœ… [DepthProLocal] æ¨¡å‹åŠ è½½å®Œæˆ")

        except ImportError as e:
            raise ImportError(
                "è¯·å®‰è£… Depth Pro: pip install git+https://github.com/apple/ml-depth-pro.git"
            ) from e
        except Exception as e:
            raise RuntimeError(f"Depth Pro æ¨¡å‹åŠ è½½å¤±è´¥: {e}") from e

    def infer(self, crop_bytes: bytes) -> DepthEstimation:
        """
        å¯¹å›¾åƒè£å‰ªè¿›è¡Œæ·±åº¦ä¼°è®¡

        Args:
            crop_bytes: PNG/JPEG æ ¼å¼çš„å›¾åƒå­—èŠ‚æµ

        Returns:
            DepthEstimation åŒ…å«æ·±åº¦å›¾å’Œç»Ÿè®¡ä¿¡æ¯
        """
        import torch

        # åŠ è½½å›¾åƒ
        image = Image.open(BytesIO(crop_bytes)).convert("RGB")

        # é¢„å¤„ç†
        image_tensor = self.transform(image).to(self.device)

        # æ¨ç†
        with torch.no_grad():
            prediction = self.model.infer(image_tensor)

        # æå–æ·±åº¦å›¾
        depth_map = prediction["depth"].cpu().numpy().squeeze()

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        min_depth = float(depth_map.min())
        max_depth = float(depth_map.max())
        median_depth = float(np.median(depth_map))

        return DepthEstimation(
            depth_map=depth_map,
            min_depth=min_depth,
            max_depth=max_depth,
            median_depth=median_depth,
            raw={
                "shape": depth_map.shape,
                "dtype": str(depth_map.dtype),
            },
        )

    def __del__(self):
        """æ¸…ç† GPU èµ„æº"""
        if self.model is not None:
            del self.model
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except:
                pass
